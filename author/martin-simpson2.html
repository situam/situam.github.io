<!DOCTYPE html>
<html>
<head>
    <title>... - Articles by Martin Simpson</title>
  <meta charset="utf-8" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Literata:regular,italic,bold|Roboto+Mono:wght@450">
  <link rel="stylesheet" type="text/css" href="/theme/css/style.css">

</head>

<body>

  <section id="nav">
    <header>
      <h1><a href="/">...</a></h1>
    </header>
    <nav id="menu"><ul>
      <li><a href="/meta/">meta/</a></li>
      <li><a href="/modules/">modules/</a></li>
      <li><a href="/modules/archive/">modules/archive/</a></li>
      <li><a href="/modules/pd/">modules/pd/</a></li>
      <li><a href="/plans/">plans/</a></li>
      <li><a href="/records/">records/</a></li>
    </ul></nav>
  </section>

  <section id="content">




  <p><a href="http://situ.am">situ.am</a> is a live archive/annotator/working tool for experiments in real-time composition and emergence in meanderings. slow-evolving sounds in a process that is itself slow-evolving, a system for remembering and remembering to remember:</p>
<ul>
<li>rhizomatic interferences in perceiver-environment feedback-loop dialogues</li>
<li>aesthetics of the spaces in-between, rests, liminal delaylines</li>
<li>audibly self-referential structures, isomorphisms</li>
<li>vertical sound</li>
<li>masking, entropy decreasing, affording space for meandering attention</li>
<li>extended duration in musical composition</li>
<li>interference patterns filtered-&gt;filtered again</li>
</ul>
<blockquote>
<p>you can't will spontaneity. but you can introduce it with a pair of scissors.<br />
– william burroughs, the third mind</p>
</blockquote>
<h3>structure and process</h3>
<p><img alt="metamap" src="/media/2020-07-14_metamap.jpg" /></p>
<p>pursuing a cyclic process of experimenting, capturing, listening again, and preparing, the work embraces a spirit of meandering – in a physical sense, of slowly changing environments, and stopping at the places in-between, mediating in real-time the experience with the immediate soundscape – and recording. to experience recordings afterwards is to filter them through the capturing device and and listening device and through the listening situation in a later time and place.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.08.25/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/cut-up-permuting-sampler">cut-up permuting sampler</a></h2>
  <!--<div class="meta"></div>-->




  <p>(transcribed from voice memo, 2020-04-27)</p>
<p>record spoken phrase/percusive beats/etc into sample<br />
detect transients by peak/threshold-following<br />
trigger permutations of cut-up sample playback, eg:</p>
<p>abcdefg<br />
gfedcba<br />
abababa<br />
fedfedf</p>
<p>optionally have multiple recordings of same phrase/beats, to add variety to chose from</p>
<ul>
<li>try with web audio</li>
<li>progressive web app (saveable to homescreen, fullscreen, offline?)</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.08.16/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/pepe">pepe</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-08-16_231252.mp3"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.08.05/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/in-a-tree-t02">in a tree t02</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-08-05_195612.mp3"></div>
        <div class="sf" id="2020-08-05_195848.mp3"></div>
        <div class="sf" id="2020-08-05_202122.mp3"></div>
        <div class="sf" id="2020-08-05_203858.mp3"></div>
        <div class="sf" id="2020-08-05_205834.mp3"></div>
        <div class="sf" id="2020-08-05_211028.mp3"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.08.03/records | Brüsseler Platz</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/brusseler-platz-t03">Brüsseler Platz T03</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-08-05_130816.mp3"></div>
        <div class="sf" id="2020-08-05_134146.mp3"></div>
        <div class="sf" id="2020-08-05_141352.mp3"></div>

  <p>[todo] get recordings from felix's zoom<br />
- photos from thiago<br />
- photo of marie</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.30/modules/archive | <a href="/roadmap/">roadmap</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/archive/annotator">annotator</a></h2>
  <!--<div class="meta">  <a href="/roadmap/">roadmap</a>  </div>-->




  <p>annotator _ presents recordings with possibly defined start position, end position, highlighted/annotate regions, and regions marked for removal (which are skipped over), offering an easy and potentially collaborative in-browser possibility of annotatating and non-destructively presenting snippets in the context of their longer recordings. regions made can be exported to a reaper project.</p>
<p>how to use:</p>
<ul>
<li>click on recording to load soundfile, waveform, and start playing</li>
<li>click and drag on waveform to create and select region</li>
<li>type to annotate (some commands are interpreted):</li>
<li><code>start</code><ul>
<li>sets start position, fades in length of region</li>
</ul>
</li>
<li><code>end</code><ul>
<li>sets end position, fades out length of region</li>
</ul>
</li>
<li><code>rm</code><ul>
<li>skips region with fade-in/fade-out</li>
<li>currently set to 500 ms fade</li>
<li>[ ] add variable fade-in/fade-out times<ul>
<li>eg. <code>rm 500</code></li>
</ul>
</li>
<li>[ ] add crossfade</li>
</ul>
</li>
</ul>
<p>note: adding/changing annotations is currently password-protected<br />
  - [ ] add guest user login</p>
<h3>roadmap</h3>
<ul>
<li>[ ] offline mode</li>
<li>[ ] video player - annotate video</li>
<li>[ ] add highlight/star/rating capability</li>
<li>[ ] fix sometimes being overwritten bug</li>
<li>[ ] add play/pause button next to waveform</li>
<li>[ ] display file length</li>
<li>[ ] mark recordings for removal (syntax: rename with 'rm' at start of )</li>
<li>[ ] for slomo videos: option to change playback speed and set+save default playspeed. how to deal with the slow-motion recordings (120fps captured on iPhone 5s)? maybe the annotator shows the fps and exposes the option to change playback speed, with the last-selected setting sticking?</li>
<li>how to display multitude of files connecting to single recording moment? small mixer between mic input and sound output with preset setting?</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.30/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/out-recorder">out-recorder~</a></h2>
  <!--<div class="meta"></div>-->




  <p>stereo audio monitor and recorder. toggling record outputs two stereo .wav files to the disk - the audio sent to the first two inlets (x.wav) and the stereo microphone in (x-adc.wav). filenames are incremented. while recording, marks can be made, output to a text file on the disk. after recording, a voicememo can be optionally recorded from the microphone in (named as x-vm.wav).</p>
<p>requires <code>rec-count.txt</code> to keep count.</p>
<p>inlets: in-L, in-R, message</p>
<p>messages:</p>
<ul>
<li><code>[/rec 1(</code> start recording two stereo audio files (inlets 1 2, adc~ 1 2)</li>
<li><code>[/rec 0(</code> stop recording</li>
<li><code>[/rec-voicememo 1(</code> start recording voicememo</li>
<li><code>[/rec-voicememo 1(</code> stop recording voicememo</li>
<li><code>[/mark 1(</code> outputs index of file followed by timestamp to <code>markers.txt</code></li>
</ul>
<p><a href="/patches/out-recorder~/out-recorder~.zip">out-recorder~.zip</a></p>
  </div>




  <p>a collection of pieces to be put together in varying configurations</p>
  </div>




  <p>a place to keep ideas and plans to work on later</p>
<ul>
<li>[ ] fill archive with experiments already done</li>
<li>[ ] add khg t01</li>
<li>[ ] add soundscape 1&amp;2 with felix</li>
<li>[ ] add visuals from bozen, tunnel, eifel</li>
<li>[ ] go through proposal, create experiments/modules for each element</li>
<li>[ ] document modules + at least one test demoing</li>
<li>[ ] phase looper. from one loop (maybe tail of a banjo/piano key) create two loops, 1 unit length and 1.01(?) unit length. filter one slowly up, filter other slowly down.</li>
<li>[x] asynchronous piano/synth loops playing on pitchshift-delay</li>
</ul>
  </div>




  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Title: emergence Pages: 1 -->
<svg width="496pt" height="103pt"
 viewBox="0.00 0.00 495.96 103.42" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 99.42)">
<title>emergence</title>
<!-- audiosystem -->
<g id="node1" class="node">
<title>audiosystem</title>
<g id="a_node1"><a xlink:href="http://example.com/1" xlink:title="audio system">
<ellipse fill="none" stroke="black" cx="57.84" cy="-64" rx="57.69" ry="18"/>
<text text-anchor="middle" x="57.84" y="-60.3" font-family="Times,serif" font-size="14.00">audio system</text>
</a>
</g>
</g>
<!-- imprint in space -->
<g id="node2" class="node">
<title>imprint in space</title>
<ellipse fill="none" stroke="black" cx="219.93" cy="-64" rx="68.49" ry="18"/>
<text text-anchor="middle" x="219.93" y="-60.3" font-family="Times,serif" font-size="14.00">imprint in space</text>
</g>
<!-- audiosystem&#45;&gt;imprint in space -->
<g id="edge1" class="edge">
<title>audiosystem&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M115.74,-64C124.07,-64 132.77,-64 141.43,-64"/>
<polygon fill="black" stroke="black" points="141.55,-67.5 151.55,-64 141.55,-60.5 141.55,-67.5"/>
</g>
<!-- field recorder -->
<g id="node4" class="node">
<title>field recorder</title>
<ellipse fill="none" stroke="black" cx="406.07" cy="-18" rx="57.69" ry="18"/>
<text text-anchor="middle" x="406.07" y="-14.3" font-family="Times,serif" font-size="14.00">field recorder</text>
</g>
<!-- audiosystem&#45;&gt;field recorder -->
<g id="edge5" class="edge">
<title>audiosystem&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M97.72,-50.74C114.18,-45.63 133.68,-40.26 151.69,-37 214.23,-25.69 286.63,-21.09 337.98,-19.23"/>
<polygon fill="black" stroke="black" points="338.41,-22.72 348.29,-18.89 338.18,-15.73 338.41,-22.72"/>
</g>
<!-- perciever&#45;performer -->
<g id="node3" class="node">
<title>perciever&#45;performer</title>
<ellipse fill="none" stroke="black" cx="406.07" cy="-72" rx="81.79" ry="18"/>
<text text-anchor="middle" x="406.07" y="-68.3" font-family="Times,serif" font-size="14.00">perciever&#45;performer</text>
</g>
<!-- imprint in space&#45;&gt;perciever&#45;performer -->
<g id="edge2" class="edge">
<title>imprint in space&#45;&gt;perciever&#45;performer</title>
<path fill="none" stroke="black" d="M286.89,-60.36C299.72,-60.67 313.29,-61.2 326.47,-61.9"/>
<polygon fill="black" stroke="black" points="326.29,-65.39 336.47,-62.47 326.68,-58.41 326.29,-65.39"/>
</g>
<!-- imprint in space&#45;&gt;field recorder -->
<g id="edge6" class="edge">
<title>imprint in space&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M270.28,-51.67C295.01,-45.49 325.03,-37.99 350.46,-31.64"/>
<polygon fill="black" stroke="black" points="351.46,-35 360.32,-29.18 349.77,-28.21 351.46,-35"/>
</g>
<!-- perciever&#45;performer&#45;&gt;audiosystem -->
<g id="edge3" class="edge">
<title>perciever&#45;performer&#45;&gt;audiosystem</title>
<path fill="none" stroke="black" d="M344.41,-83.87C292.93,-92.2 217.2,-100.33 151.69,-91 136.57,-88.85 120.46,-84.81 105.99,-80.51"/>
<polygon fill="black" stroke="black" points="106.85,-77.11 96.26,-77.5 104.78,-83.8 106.85,-77.11"/>
</g>
<!-- perciever&#45;performer&#45;&gt;imprint in space -->
<g id="edge4" class="edge">
<title>perciever&#45;performer&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M325.5,-75.24C313.54,-74.82 301.29,-74.25 289.58,-73.53"/>
<polygon fill="black" stroke="black" points="289.65,-70.03 279.45,-72.88 289.2,-77.02 289.65,-70.03"/>
</g>
</g>
</svg>

<p>unedited recordings of experiments, real-time, in situ soundscape mediations</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.30/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/container">container</a></h2>
  <!--<div class="meta"></div>-->



        <video src="/media/2020-07-30_194245.mp4#vertical" controls></video>

  <p>a container MobMuPlat patch for pure data modules that currently consists of that runs on iphone:</p>
<ul>
<li>5d routing matrix for on-the-fly routing with scheduled attenuation fades between:</li>
<li>2 filters</li>
<li>2 pitch shift delays</li>
<li>2 loopers</li>
<li>buffer looper</li>
<li>recording module</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.30/modules/archive </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/archive/website">website</a></h2>
  <!--<div class="meta"></div>-->




  <p>the website is built on <a href="">pelican</a>, a static generator that converts folders of markdown files to a static site. this allows the entire structure of the site to exist simply as text files with minimal markup. it is mostly used as is, aside for the addition of the annotator javascript app, the flow of which is as follows:</p>
<p>add session entry, all fields optional:</p>
<pre><code>YYYY-MM-DD_test-entry.md

---
title: no title
date: YYYY-MM-DD
media: *.mp3, *.mp4, *.mp3
cover: *.jpg
---

some description
</code></pre>

<p>the list of media files specified in the yaml metadata output a list of <code>div</code>s:</p>
<pre><code>&lt;div class=&quot;sfplayer&quot; id=&quot;soundfile-1.mp3&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;sfplayer&quot; id=&quot;soundfile-2.mp3&quot;&gt;&lt;/div&gt;
&lt;div class=&quot;sfplayer&quot; id=&quot;soundfile-3.mp3&quot;&gt;&lt;/div&gt;
&lt;script src=&quot;app.js&quot;&gt;&lt;/script&gt;
</code></pre>

<p><code>app.js</code> on page load fills in each div with a sound file player interface. then it checks if there exist annotations for the soundfile, which are saved simply as .json files on a (currently separate) PHP server. if there are, a list of (labeled) regions and a title are filled in.</p>
<p>the title is content-editable, meaning it can be edited directly on the page, and any changes made are saved live back to the soundfile.json file. any changes to the annotations are similarly auto-saved to the server. the php scripts that handle this are placed in a password-protected folder on the server, making for a crude but functional at this scale authentication-required to make changes to the annotations.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.29/records | Brüsseler Platz</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/brusseler-platz-t02">Brüsseler Platz T02</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-29_123928.mp3"></div>
        <div class="sf" id="2020-07-29_124412.mp3"></div>
        <div class="sf" id="2020-07-29_125510.mp3"></div>
        <div class="sf" id="2020-07-29_125938.mp3"></div>
        <div class="sf" id="2020-07-29_130848.mp3"></div>
        <div class="sf" id="2020-07-29_131320.mp3"></div>
        <div class="sf" id="2020-07-29_131606.mp3"></div>
        <div class="sf" id="2020-07-29_132830.mp3"></div>
        <div class="sf" id="2020-07-29_1333.mp3"></div>
        <div class="sf" id="2020-07-29_134514.mp3"></div>
        <div class="sf" id="2020-07-29_1349.mp3"></div>
        <div class="sf" id="2020-07-29_141138.mp3"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.07.29/plans </div>
  </div>
  <div class="entry-content">
  <h2><a href="/plans/website-as-ambient-player">website as ambient player</a></h2>
  <!--<div class="meta"></div>-->




  <p>getting into web audio for the the annotator exposed the potential of using the website as more than just a static dry serving of snippets</p>
<p>for example:<br />
- cut-up/juxtaposing two randomly selected recording to create new interactions between them.<br />
  - maybe suggested pairings of recordings? and slow fade in and outs, ala <a href="">mynoise.net</a></p>
<p>progress:</p>
<p>situ.am/juxtapose<br />
website that overlays two randomly-selected video files from a public google drive folder. successfully  accesses drive folder and overlays videos with css blending modes.</p>
<p>(wishing to still smooth more the process of getting recordings onto an accessible website, decided to look into google drive implementation, opening up the possibility of, for example, directly saving iphone recordings to this folder, and easily opening up the process to others)</p>
<p>try:<br />
- randomly overlay highlighted regions of two audio files</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.28/modules </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/portable-collection">portable collection</a></h2>
  <!--<div class="meta"></div>-->




  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Title: G Pages: 1 -->
<svg width="294pt" height="260pt"
 viewBox="0.00 0.00 293.66 260.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 256)">
<title>G</title>
<!-- field recorder -->
<g id="node1" class="node">
<title>field recorder</title>
<ellipse fill="none" stroke="black" cx="223.01" cy="-162" rx="57.69" ry="18"/>
<text text-anchor="middle" x="223.01" y="-158.3" font-family="Times,serif" font-size="14.00">field recorder</text>
</g>
<!-- iphone -->
<g id="node2" class="node">
<title>iphone</title>
<ellipse fill="none" stroke="black" cx="87.01" cy="-90" rx="34.39" ry="18"/>
<text text-anchor="middle" x="87.01" y="-86.3" font-family="Times,serif" font-size="14.00">iphone</text>
</g>
<!-- field recorder&#45;&gt;iphone -->
<g id="edge2" class="edge">
<title>field recorder&#45;&gt;iphone</title>
<path fill="none" stroke="black" d="M194.5,-146.33C172.73,-135.12 142.7,-119.66 119.91,-107.93"/>
<polygon fill="black" stroke="black" points="121.44,-104.78 110.95,-103.32 118.24,-111.01 121.44,-104.78"/>
</g>
<!-- in&#45;ear monitors -->
<g id="node3" class="node">
<title>in&#45;ear monitors</title>
<ellipse fill="none" stroke="black" cx="220.01" cy="-18" rx="65.79" ry="18"/>
<text text-anchor="middle" x="220.01" y="-14.3" font-family="Times,serif" font-size="14.00">in&#45;ear monitors</text>
</g>
<!-- field recorder&#45;&gt;in&#45;ear monitors -->
<g id="edge3" class="edge">
<title>field recorder&#45;&gt;in&#45;ear monitors</title>
<path fill="none" stroke="black" d="M222.65,-143.87C222.14,-119.67 221.2,-75.21 220.59,-46.39"/>
<polygon fill="black" stroke="black" points="224.09,-46.11 220.38,-36.19 217.09,-46.26 224.09,-46.11"/>
</g>
<!-- iphone&#45;&gt;in&#45;ear monitors -->
<g id="edge1" class="edge">
<title>iphone&#45;&gt;in&#45;ear monitors</title>
<path fill="none" stroke="black" d="M110.48,-76.65C130.15,-66.3 158.61,-51.32 181.59,-39.22"/>
<polygon fill="black" stroke="black" points="183.52,-42.16 190.74,-34.41 180.26,-35.97 183.52,-42.16"/>
</g>
<!-- ms&#45;2 amp -->
<g id="node6" class="node">
<title>ms&#45;2 amp</title>
<ellipse fill="none" stroke="black" cx="87.01" cy="-18" rx="46.59" ry="18"/>
<text text-anchor="middle" x="87.01" y="-14.3" font-family="Times,serif" font-size="14.00">ms&#45;2 amp</text>
</g>
<!-- iphone&#45;&gt;ms&#45;2 amp -->
<g id="edge7" class="edge">
<title>iphone&#45;&gt;ms&#45;2 amp</title>
<path fill="none" stroke="black" d="M87.01,-71.7C87.01,-63.98 87.01,-54.71 87.01,-46.11"/>
<polygon fill="black" stroke="black" points="90.51,-46.1 87.01,-36.1 83.51,-46.1 90.51,-46.1"/>
</g>
<!-- em172 omni mic capsules -->
<g id="node4" class="node">
<title>em172 omni mic capsules</title>
<ellipse fill="none" stroke="black" cx="105.01" cy="-234" rx="104.78" ry="18"/>
<text text-anchor="middle" x="105.01" y="-230.3" font-family="Times,serif" font-size="14.00">em172 omni mic capsules</text>
</g>
<!-- em172 omni mic capsules&#45;&gt;field recorder -->
<g id="edge4" class="edge">
<title>em172 omni mic capsules&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M132.68,-216.59C149.27,-206.75 170.52,-194.14 188.24,-183.63"/>
<polygon fill="black" stroke="black" points="190.32,-186.46 197.14,-178.35 186.75,-180.44 190.32,-186.46"/>
</g>
<!-- em172 omni mic capsules&#45;&gt;iphone -->
<g id="edge5" class="edge">
<title>em172 omni mic capsules&#45;&gt;iphone</title>
<path fill="none" stroke="black" d="M54.33,-218.22C35.79,-210.09 16.73,-197.9 6.01,-180 -2.21,-166.27 -1.6,-158.07 6.01,-144 15.52,-126.41 33.69,-113.73 50.41,-105.18"/>
<polygon fill="black" stroke="black" points="51.96,-108.32 59.48,-100.86 48.95,-102 51.96,-108.32"/>
</g>
<!-- portable battery -->
<g id="node5" class="node">
<title>portable battery</title>
<ellipse fill="none" stroke="black" cx="81.01" cy="-162" rx="66.09" ry="18"/>
<text text-anchor="middle" x="81.01" y="-158.3" font-family="Times,serif" font-size="14.00">portable battery</text>
</g>
<!-- portable battery&#45;&gt;iphone -->
<g id="edge6" class="edge">
<title>portable battery&#45;&gt;iphone</title>
<path fill="none" stroke="black" d="M82.5,-143.7C83.16,-135.98 83.95,-126.71 84.69,-118.11"/>
<polygon fill="black" stroke="black" points="88.18,-118.37 85.55,-108.1 81.21,-117.77 88.18,-118.37"/>
</g>
</g>
</svg>

<p>a small collection of physical modules with different possibilities for interconnection depending on the situation that arises, chunked as follows. in assembling this kit, preference is given to small and light vs big and bulky, trying to always carry with:</p>
<ul>
<li>field recorder (olympus ls-5)</li>
<li>battery case</li>
<li>battery</li>
<li>otg+usb cable to connect field recorder to iphone</li>
<li>usb/lighting cable to charge iphone</li>
<li>iphone (running PD container patch)</li>
<li>wide angle/macro lens</li>
<li>crystal prism</li>
<li>headphone case</li>
<li>in-ear monitoring headphones</li>
<li>omni mic caps (primo em172)</li>
<li>headphone/mic splitter</li>
<li>headphone splitter</li>
</ul>
<p>sometimes also:</p>
<ul>
<li>yamaha reface cp keyboard</li>
<li>usb cable</li>
<li>ms-2 amp</li>
<li>bluetooth speaker</li>
</ul>
<h3>Digital Components</h3>
<p>iphone runs MobMuPlat, a container app for Pure Data patches, which in turn runs:</p>
<ul>
<li>
<p>container patch that holds the 5d routing matrix and modules to be developed along the way. (currently, filters, pitch-shifting delays, jumping loopers, buffer looper) (planned, resynth)</p>
</li>
<li>
<p>recorder which captures raw mic input, sound that is output, and a voicememo</p>
</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.26/records | stadtwald</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/in-a-tree">in a tree</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-26_164648.mp3"></div>
        <video src="/media/2020-07-26.mp4" controls></video>
        <div class="sf" id="2020-07-26_171540.mp3"></div>
        <div class="sf" id="2020-07-26_172942.mp3"></div>

  <p>short afternoon break to test a delay pedal, two hammocks happened packed, reface cp + moog synth app. echoes of khg plays.</p>
<p>next time: hang mics</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.25/records | Siebengebirge</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/hulle">hülle</a></h2>
  <!--<div class="meta"></div>-->


  <img src="/media/2020-07-25.jpg">

        <div class="sf" id="2020-07-25_114617_73-adc.mp3"></div>
        <div class="sf" id="2020-07-25_114617_73.mp3"></div>
        <div class="sf" id="2020-07-25_114720.mp3"></div>
        <div class="sf" id="2020-07-25_121704.mp3"></div>
        <div class="sf" id="2020-07-25_123822.mp3"></div>
        <div class="sf" id="2020-07-25_124932.mp3"></div>

  <p>on the train over:<br />
- got the improved routing matrix interface working on the train over<br />
- agreed to set felix up with a simple one-page site that creates annotation entries for recordings, editable by anyone (maybe password-protected)<br />
- make appointments in nice places and get ready on the way...</p>
<p>balancing giving and taking in a space, active/passive, listening/sounding. cold and dark, still air, sensory deprivation.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.25/records | Königswinter</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/rheinrohr">rheinröhr</a></h2>
  <!--<div class="meta"></div>-->


  <img src="/media/2020-07-25_1708.jpg">

        <div class="sf" id="2020-07-25_151819_76-adc.mp3"></div>
        <div class="sf" id="2020-07-25_151819_76.mp3"></div>
        <div class="sf" id="2020-07-25_151827_76-vm.mp3"></div>
        <div class="sf" id="2020-07-25_154858_77-adc.mp3"></div>
        <div class="sf" id="2020-07-25_154858_77.mp3"></div>
        <div class="sf" id="2020-07-25_154906_77-vm.mp3"></div>
        <div class="sf" id="2020-07-25_155254_78-adc.mp3"></div>
        <div class="sf" id="2020-07-25_155254_78.mp3"></div>
        <div class="sf" id="2020-07-25_160252_79-adc.mp3"></div>
        <div class="sf" id="2020-07-25_161534_80-adc.mp3"></div>
        <div class="sf" id="2020-07-25_161534_80.mp3"></div>
        <div class="sf" id="2020-07-25_161811_80-vm.mp3"></div>
        <div class="sf" id="2020-07-25_162834.mp3"></div>
        <div class="sf" id="2020-07-25_164001_81-adc.mp3"></div>
        <div class="sf" id="2020-07-25_164001_81.mp3"></div>

  <p>finally found the pipe not looking for it.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.23/records | P17</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/testing-routing-matrix">testing routing matrix</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-23_132211_71-adc.mp3"></div>
        <div class="sf" id="2020-07-23_132211_71.mp3"></div>

  <p>testing small compact battery-powered setup: reface cp, marshall ms-2, ma</p>
<p>+<br />
flexible routing into pitch shifters, slow changes</p>
<p>-<br />
hard to see value of loudness in the router</p>
<p>idea:<br />
- [x] changing interface so that holding down pad moves 'set value' to current value<br />
- [ ] expose loop in-out-fade time</p>
<p>^ where the process of experimentation is more interesting than the recording itself, and the experience of the process reveals desire lines and areas for improvement</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.22/modules/archive </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/archive/archiving-workflow-current-status">archiving workflow (current status)</a></h2>
  <!--<div class="meta"></div>-->




  <p>currently:</p>
<ul>
<li>recordings are made on phone (in _ app), videos, voice memos, olympus field recorder</li>
<li>after session, files saved to <code>0_process</code> folder on computer</li>
<li>running <code>process.sh</code> script inside this folder:<ul>
<li>prepends/renames files with creation timestamp</li>
</ul>
</li>
<li>converts/compresses each file to the relevant filetype for the web-friendly archive<ul>
<li>mov: mp4</li>
<li>wav, aac: mp3</li>
</ul>
</li>
<li>moves the original files to <code>1_originals</code></li>
<li>moves the compressed files to <code>{static}/media</code> folder</li>
<li>generates a markdown session file</li>
</ul>
<p>folder structure:</p>
<pre><code>| 0_process
  | *.mov
  | *.wav
  | *.aac
  | process.sh

| 1_originals

</code></pre>

<p>markdown file</p>
<pre><code>---
title: (insert title here)
date: YYYY-MM-DD
media: *.mp3, *.mp4, *.mp3
---

(insert description/related notes/ideas here, before forgetting)
</code></pre>

<p>ideally:</p>
<ul>
<li>save to dropbox/google drive folder</li>
<li>server-side watcher auto converts and generates entry?</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.21/records | Münster</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/munster-kirche">Münster Kirche</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-21_152824.mp3"></div>
        <div class="sf" id="2020-07-21_160126.mp3"></div>
        <div class="sf" id="2020-07-21_161050.mp3"></div>
        <video src="/media/2020-07-21_1615.mp4" controls></video>
        <div class="sf" id="2020-07-21_175118.mp3"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.07.20/records | Duisburg</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/landschaftspark-duisburg">Landschaftspark Duisburg</a></h2>
  <!--<div class="meta"></div>-->


  <img src="/media/2020-07-20_140218.jpg">

        <div class="sf" id="2020-07-20_114708_LS_50540.mp3"></div>
        <div class="sf" id="2020-07-20_120328_LS_50542.mp3"></div>
        <div class="sf" id="2020-07-20_135622_LS_50543.mp3"></div>
        <div class="sf" id="2020-07-20_140940_68-adc.mp3"></div>
        <div class="sf" id="2020-07-20_140940_68.mp3"></div>
        <div class="sf" id="2020-07-20_141610_69-adc.mp3"></div>
        <div class="sf" id="2020-07-20_141610_69.mp3"></div>
        <div class="sf" id="2020-07-20_141657_69-vm.mp3"></div>
        <div class="sf" id="2020-07-20_143847_70-adc.mp3"></div>
        <div class="sf" id="2020-07-20_143847_70.mp3"></div>
        <div class="sf" id="2020-07-20_145422_LS_50544.mp3"></div>
        <div class="sf" id="2020-07-20_213536_LS_50545.mp3"></div>

  <p><img alt="portable setup" src="/media/2020-07-20_135944.jpg" /></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.20/records | <a href="/feedback/">feedback</a>   | Baustelle, Krefeld</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/rohrklang">Rohrklang</a></h2>
  <!--<div class="meta">  <a href="/feedback/">feedback</a>  </div>-->



        <div class="sf" id="2020-07-20_091042_62-adc.mp3"></div>
        <div class="sf" id="2020-07-20_091042_62.mp3"></div>
        <div class="sf" id="2020-07-20_094934_LS_50539.mp3"></div>
        <div class="sf" id="2020-07-20_095719_63-adc.mp3"></div>
        <div class="sf" id="2020-07-20_095719_63.mp3"></div>
        <div class="sf" id="2020-07-20_095742_63-vm.mp3"></div>
        <div class="sf" id="2020-07-20_101243_64-adc.mp3"></div>
        <div class="sf" id="2020-07-20_101243_64.mp3"></div>
        <div class="sf" id="2020-07-20_101710_65-adc.mp3"></div>
        <div class="sf" id="2020-07-20_101710_65.mp3"></div>
        <div class="sf" id="2020-07-20_102204_66-adc.mp3"></div>
        <div class="sf" id="2020-07-20_102204_66.mp3"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.07.13/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/fft-filter">fft filter</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-13_134802.mp3"></div>
        <video src="/media/2020-07-13_125740.mp4" controls></video>
        <video src="/media/2020-07-13_123238_fft-filter.mp4" controls></video>
        <video src="/media/2020-07-15_142544.mp4" controls></video>

  <p>on the way to a fft resynth</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.13/meta </div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/mindmap">mindmap</a></h2>
  <!--<div class="meta"></div>-->




  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Pages: 1 -->
<svg width="1279pt" height="620pt"
 viewBox="0.00 0.00 1278.63 620.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 616)">
<g id="clust8" class="cluster">
<title>cluster</title>
<polygon fill="transparent" stroke="black" stroke-dasharray="1,5" points="1076.63,-136 1076.63,-404 1250.63,-404 1250.63,-136 1076.63,-136"/>
</g>
<!-- feedback -->
<g id="node1" class="node">
<title>feedback</title>
<ellipse fill="none" stroke="black" cx="370.63" cy="-594" rx="42.49" ry="18"/>
<text text-anchor="middle" x="370.63" y="-590.3" font-family="Times,serif" font-size="14.00">feedback</text>
</g>
<!-- improvisation -->
<g id="node2" class="node">
<title>improvisation</title>
<ellipse fill="none" stroke="black" cx="370.63" cy="-522" rx="59.59" ry="18"/>
<text text-anchor="middle" x="370.63" y="-518.3" font-family="Times,serif" font-size="14.00">improvisation</text>
</g>
<!-- feedback&#45;&#45;improvisation -->
<g id="edge2" class="edge">
<title>feedback&#45;&#45;improvisation</title>
<path fill="none" stroke="black" d="M370.63,-575.7C370.63,-564.85 370.63,-550.92 370.63,-540.1"/>
</g>
<!-- free play -->
<g id="node3" class="node">
<title>free play</title>
<ellipse fill="none" stroke="black" cx="257.63" cy="-450" rx="42.49" ry="18"/>
<text text-anchor="middle" x="257.63" y="-446.3" font-family="Times,serif" font-size="14.00">free play</text>
</g>
<!-- feedback&#45;&#45;free play -->
<g id="edge3" class="edge">
<title>feedback&#45;&#45;free play</title>
<path fill="none" stroke="black" d="M346.98,-578.8C332.5,-569.23 314.38,-555.53 301.63,-540 283.47,-517.89 270.36,-487.03 263.39,-468.07"/>
</g>
<!-- performance ecosystem -->
<g id="node4" class="node">
<title>performance ecosystem</title>
<ellipse fill="none" stroke="black" cx="917.63" cy="-162" rx="94.78" ry="18"/>
<text text-anchor="middle" x="917.63" y="-158.3" font-family="Times,serif" font-size="14.00">performance ecosystem</text>
</g>
<!-- feedback&#45;&#45;performance ecosystem -->
<g id="edge4" class="edge">
<title>feedback&#45;&#45;performance ecosystem</title>
<path fill="none" stroke="black" d="M410.59,-587.97C542.68,-570.45 961.34,-507.46 1039.63,-404 1097.21,-327.9 986.15,-220.5 938.18,-179.65"/>
</g>
<!-- recursion -->
<g id="node23" class="node">
<title>recursion</title>
<ellipse fill="none" stroke="black" cx="1178.63" cy="-234" rx="43.59" ry="18"/>
<text text-anchor="middle" x="1178.63" y="-230.3" font-family="Times,serif" font-size="14.00">recursion</text>
</g>
<!-- feedback&#45;&#45;recursion -->
<g id="edge41" class="edge">
<title>feedback&#45;&#45;recursion</title>
<path fill="none" stroke="black" d="M412.71,-591.73C544.27,-587.46 946.47,-572.06 1072.63,-540 1166.14,-516.23 1270.63,-547.48 1270.63,-451 1270.63,-451 1270.63,-451 1270.63,-377 1270.63,-323.54 1224.13,-274.32 1197.25,-250.33"/>
</g>
<!-- improvisation&#45;&#45;free play -->
<g id="edge1" class="edge">
<title>improvisation&#45;&#45;free play</title>
<path fill="none" stroke="black" d="M345.55,-505.46C326.17,-493.46 299.57,-476.98 280.71,-465.3"/>
</g>
<!-- real&#45;time composition -->
<g id="node6" class="node">
<title>real&#45;time composition</title>
<ellipse fill="none" stroke="black" cx="713.63" cy="-450" rx="89.08" ry="18"/>
<text text-anchor="middle" x="713.63" y="-446.3" font-family="Times,serif" font-size="14.00">real&#45;time composition</text>
</g>
<!-- improvisation&#45;&#45;real&#45;time composition -->
<g id="edge19" class="edge">
<title>improvisation&#45;&#45;real&#45;time composition</title>
<path fill="none" stroke="black" d="M418.68,-511.19C480.08,-498.66 586.38,-476.97 653.2,-463.33"/>
</g>
<!-- meandering -->
<g id="node15" class="node">
<title>meandering</title>
<ellipse fill="none" stroke="black" cx="370.63" cy="-450" rx="52.79" ry="18"/>
<text text-anchor="middle" x="370.63" y="-446.3" font-family="Times,serif" font-size="14.00">meandering</text>
</g>
<!-- improvisation&#45;&#45;meandering -->
<g id="edge20" class="edge">
<title>improvisation&#45;&#45;meandering</title>
<path fill="none" stroke="black" d="M370.63,-503.7C370.63,-492.85 370.63,-478.92 370.63,-468.1"/>
</g>
<!-- strategisch&#45;geplante spontänitatet -->
<g id="node5" class="node">
<title>strategisch&#45;geplante spontänitatet</title>
<ellipse fill="none" stroke="black" cx="1014.63" cy="-90" rx="128.08" ry="18"/>
<text text-anchor="middle" x="1014.63" y="-86.3" font-family="Times,serif" font-size="14.00">strategisch&#45;geplante spontänitatet</text>
</g>
<!-- performance ecosystem&#45;&#45;strategisch&#45;geplante spontänitatet -->
<g id="edge9" class="edge">
<title>performance ecosystem&#45;&#45;strategisch&#45;geplante spontänitatet</title>
<path fill="none" stroke="black" d="M940.62,-144.41C955.97,-133.33 976.08,-118.82 991.47,-107.71"/>
</g>
<!-- performance ecosystem&#45;&#45;real&#45;time composition -->
<g id="edge10" class="edge">
<title>performance ecosystem&#45;&#45;real&#45;time composition</title>
<path fill="none" stroke="black" d="M912.67,-180.16C902.67,-212.1 877.34,-281.33 834.63,-324 809.88,-348.73 789.92,-335.83 764.63,-360 743,-380.67 727.79,-412.54 719.9,-432.01"/>
</g>
<!-- field recording -->
<g id="node7" class="node">
<title>field recording</title>
<ellipse fill="none" stroke="black" cx="858.63" cy="-18" rx="62.29" ry="18"/>
<text text-anchor="middle" x="858.63" y="-14.3" font-family="Times,serif" font-size="14.00">field recording</text>
</g>
<!-- performance ecosystem&#45;&#45;field recording -->
<g id="edge11" class="edge">
<title>performance ecosystem&#45;&#45;field recording</title>
<path fill="none" stroke="black" d="M901.83,-144.1C893.45,-134.26 883.66,-121.21 877.63,-108 866.86,-84.43 862.09,-54.53 860.06,-36.09"/>
</g>
<!-- listening -->
<g id="node8" class="node">
<title>listening</title>
<ellipse fill="none" stroke="black" cx="671.63" cy="-378" rx="40.89" ry="18"/>
<text text-anchor="middle" x="671.63" y="-374.3" font-family="Times,serif" font-size="14.00">listening</text>
</g>
<!-- performance ecosystem&#45;&#45;listening -->
<g id="edge12" class="edge">
<title>performance ecosystem&#45;&#45;listening</title>
<path fill="none" stroke="black" d="M893.95,-179.59C881.61,-189.14 866.97,-202.01 856.63,-216 825.39,-258.23 846.67,-287.78 808.63,-324 800.64,-331.61 740.88,-353.14 702.97,-366.3"/>
</g>
<!-- strategisch&#45;geplante spontänitatet&#45;&#45;real&#45;time composition -->
<g id="edge5" class="edge">
<title>strategisch&#45;geplante spontänitatet&#45;&#45;real&#45;time composition</title>
<path fill="none" stroke="black" d="M1020.68,-108.22C1026.16,-126.77 1031.93,-156.76 1021.63,-180 982.98,-267.15 940.18,-268.54 862.63,-324 835.77,-343.21 822.69,-338.49 797.63,-360 778.88,-376.1 780.44,-385.88 763.63,-404 754.41,-413.93 743.28,-424.1 733.87,-432.26"/>
</g>
<!-- strategisch&#45;geplante spontänitatet&#45;&#45;field recording -->
<g id="edge6" class="edge">
<title>strategisch&#45;geplante spontänitatet&#45;&#45;field recording</title>
<path fill="none" stroke="black" d="M978.05,-72.59C951.67,-60.75 916.37,-44.91 891,-33.53"/>
</g>
<!-- real&#45;time composition&#45;&#45;listening -->
<g id="edge7" class="edge">
<title>real&#45;time composition&#45;&#45;listening</title>
<path fill="none" stroke="black" d="M703.46,-432.05C696.86,-421.05 688.29,-406.76 681.7,-395.79"/>
</g>
<!-- walking -->
<g id="node16" class="node">
<title>walking</title>
<ellipse fill="none" stroke="black" cx="148.63" cy="-378" rx="38.99" ry="18"/>
<text text-anchor="middle" x="148.63" y="-374.3" font-family="Times,serif" font-size="14.00">walking</text>
</g>
<!-- real&#45;time composition&#45;&#45;walking -->
<g id="edge21" class="edge">
<title>real&#45;time composition&#45;&#45;walking</title>
<path fill="none" stroke="black" d="M644.21,-438.67C626.44,-436.25 607.35,-433.84 589.63,-432 415.46,-413.88 365.13,-451.66 196.63,-404 187.77,-401.49 178.66,-397.24 170.79,-392.95"/>
</g>
<!-- macroform from microform -->
<g id="node20" class="node">
<title>macroform from microform</title>
<ellipse fill="none" stroke="black" cx="918.63" cy="-378" rx="111.58" ry="18"/>
<text text-anchor="middle" x="918.63" y="-374.3" font-family="Times,serif" font-size="14.00">macroform from microform</text>
</g>
<!-- real&#45;time composition&#45;&#45;macroform from microform -->
<g id="edge30" class="edge">
<title>real&#45;time composition&#45;&#45;macroform from microform</title>
<path fill="none" stroke="black" d="M757.1,-434.15C791.19,-422.52 838.48,-406.37 873.08,-394.55"/>
</g>
<!-- field recording&#45;&#45;listening -->
<g id="edge8" class="edge">
<title>field recording&#45;&#45;listening</title>
<path fill="none" stroke="black" d="M845.37,-35.82C826.62,-61.34 794.63,-112.06 794.63,-161 794.63,-235 794.63,-235 794.63,-235 794.63,-275.45 800.26,-291.92 775.63,-324 758.47,-346.34 729.29,-360.05 706.19,-367.91"/>
</g>
<!-- responding -->
<g id="node9" class="node">
<title>responding</title>
<ellipse fill="none" stroke="black" cx="716.63" cy="-306" rx="50.09" ry="18"/>
<text text-anchor="middle" x="716.63" y="-302.3" font-family="Times,serif" font-size="14.00">responding</text>
</g>
<!-- listening&#45;&#45;responding -->
<g id="edge14" class="edge">
<title>listening&#45;&#45;responding</title>
<path fill="none" stroke="black" d="M682.29,-360.41C689.36,-349.41 698.61,-335.03 705.73,-323.96"/>
</g>
<!-- attention -->
<g id="node10" class="node">
<title>attention</title>
<ellipse fill="none" stroke="black" cx="606.63" cy="-234" rx="41.69" ry="18"/>
<text text-anchor="middle" x="606.63" y="-230.3" font-family="Times,serif" font-size="14.00">attention</text>
</g>
<!-- listening&#45;&#45;attention -->
<g id="edge15" class="edge">
<title>listening&#45;&#45;attention</title>
<path fill="none" stroke="black" d="M663.92,-360.15C651.41,-332.82 626.83,-279.14 614.33,-251.82"/>
</g>
<!-- ephemerality -->
<g id="node11" class="node">
<title>ephemerality</title>
<ellipse fill="none" stroke="black" cx="425.63" cy="-306" rx="57.39" ry="18"/>
<text text-anchor="middle" x="425.63" y="-302.3" font-family="Times,serif" font-size="14.00">ephemerality</text>
</g>
<!-- listening&#45;&#45;ephemerality -->
<g id="edge16" class="edge">
<title>listening&#45;&#45;ephemerality</title>
<path fill="none" stroke="black" d="M638.2,-367.49C593.66,-354.81 514.91,-332.41 466.78,-318.71"/>
</g>
<!-- responding&#45;&#45;attention -->
<g id="edge13" class="edge">
<title>responding&#45;&#45;attention</title>
<path fill="none" stroke="black" d="M693.03,-289.98C674.09,-277.93 647.68,-261.13 629.06,-249.27"/>
</g>
<!-- delay -->
<g id="node18" class="node">
<title>delay</title>
<ellipse fill="none" stroke="black" cx="383.63" cy="-234" rx="29.8" ry="18"/>
<text text-anchor="middle" x="383.63" y="-230.3" font-family="Times,serif" font-size="14.00">delay</text>
</g>
<!-- ephemerality&#45;&#45;delay -->
<g id="edge25" class="edge">
<title>ephemerality&#45;&#45;delay</title>
<path fill="none" stroke="black" d="M415.46,-288.05C408.76,-276.89 400.03,-262.34 393.41,-251.31"/>
</g>
<!-- ambience -->
<g id="node12" class="node">
<title>ambience</title>
<ellipse fill="none" stroke="black" cx="250.63" cy="-378" rx="44.69" ry="18"/>
<text text-anchor="middle" x="250.63" y="-374.3" font-family="Times,serif" font-size="14.00">ambience</text>
</g>
<!-- soft fascinations -->
<g id="node13" class="node">
<title>soft fascinations</title>
<ellipse fill="none" stroke="black" cx="244.63" cy="-306" rx="68.49" ry="18"/>
<text text-anchor="middle" x="244.63" y="-302.3" font-family="Times,serif" font-size="14.00">soft fascinations</text>
</g>
<!-- ambience&#45;&#45;soft fascinations -->
<g id="edge17" class="edge">
<title>ambience&#45;&#45;soft fascinations</title>
<path fill="none" stroke="black" d="M249.15,-359.7C248.22,-348.85 247.02,-334.92 246.09,-324.1"/>
</g>
<!-- place language -->
<g id="node14" class="node">
<title>place language</title>
<ellipse fill="none" stroke="black" cx="94.63" cy="-306" rx="63.89" ry="18"/>
<text text-anchor="middle" x="94.63" y="-302.3" font-family="Times,serif" font-size="14.00">place language</text>
</g>
<!-- ambience&#45;&#45;place language -->
<g id="edge18" class="edge">
<title>ambience&#45;&#45;place language</title>
<path fill="none" stroke="black" d="M221.65,-364C194.87,-351.98 155.11,-334.14 127.22,-321.63"/>
</g>
<!-- meandering&#45;&#45;walking -->
<g id="edge22" class="edge">
<title>meandering&#45;&#45;walking</title>
<path fill="none" stroke="black" d="M330.97,-437.98C323.56,-435.96 315.86,-433.9 308.63,-432 258.99,-418.99 244.6,-422.2 196.63,-404 188.37,-400.87 179.71,-396.66 172.05,-392.6"/>
</g>
<!-- walking&#45;&#45;place language -->
<g id="edge23" class="edge">
<title>walking&#45;&#45;place language</title>
<path fill="none" stroke="black" d="M136.1,-360.76C127.5,-349.62 116.12,-334.87 107.46,-323.63"/>
</g>
<!-- buffer -->
<g id="node17" class="node">
<title>buffer</title>
<ellipse fill="none" stroke="black" cx="419.63" cy="-378" rx="32.49" ry="18"/>
<text text-anchor="middle" x="419.63" y="-374.3" font-family="Times,serif" font-size="14.00">buffer</text>
</g>
<!-- buffer&#45;&#45;ephemerality -->
<g id="edge24" class="edge">
<title>buffer&#45;&#45;ephemerality</title>
<path fill="none" stroke="black" d="M421.11,-359.7C422.04,-348.85 423.24,-334.92 424.16,-324.1"/>
</g>
<!-- buffer&#45;&#45;delay -->
<g id="edge26" class="edge">
<title>buffer&#45;&#45;delay</title>
<path fill="none" stroke="black" d="M397.86,-364.54C384.09,-355.32 367.46,-341.36 359.63,-324 348.64,-299.64 362.2,-269.19 372.96,-250.96"/>
</g>
<!-- delay&#45;&#45;feedback -->
<g id="edge29" class="edge">
<title>delay&#45;&#45;feedback</title>
<path fill="none" stroke="black" d="M353.63,-235.15C275.68,-236.17 69.48,-243.16 21.63,-288 -7.89,-315.66 2.63,-336.55 2.63,-377 2.63,-451 2.63,-451 2.63,-451 2.63,-521.02 237.46,-569.79 331.94,-586.57"/>
</g>
<!-- delay&#45;&#45;performance ecosystem -->
<g id="edge27" class="edge">
<title>delay&#45;&#45;performance ecosystem</title>
<path fill="none" stroke="black" d="M412.72,-229.19C493.36,-218.62 721.68,-188.69 841.73,-172.95"/>
</g>
<!-- archive -->
<g id="node19" class="node">
<title>archive</title>
<ellipse fill="none" stroke="black" cx="574.63" cy="-306" rx="36.29" ry="18"/>
<text text-anchor="middle" x="574.63" y="-302.3" font-family="Times,serif" font-size="14.00">archive</text>
</g>
<!-- archive&#45;&#45;attention -->
<g id="edge28" class="edge">
<title>archive&#45;&#45;attention</title>
<path fill="none" stroke="black" d="M582.37,-288.05C587.41,-277.05 593.94,-262.76 598.95,-251.79"/>
</g>
<!-- self&#45;reference -->
<g id="node21" class="node">
<title>self&#45;reference</title>
<ellipse fill="none" stroke="black" cx="1143.63" cy="-306" rx="59.29" ry="18"/>
<text text-anchor="middle" x="1143.63" y="-302.3" font-family="Times,serif" font-size="14.00">self&#45;reference</text>
</g>
<!-- macroform from microform&#45;&#45;self&#45;reference -->
<g id="edge31" class="edge">
<title>macroform from microform&#45;&#45;self&#45;reference</title>
<path fill="none" stroke="black" d="M967.73,-361.72C1008.46,-349.05 1065.65,-331.26 1103.63,-319.44"/>
</g>
<!-- self&#45;reference&#45;&#45;recursion -->
<g id="edge32" class="edge">
<title>self&#45;reference&#45;&#45;recursion</title>
<path fill="none" stroke="black" d="M1152.1,-288.05C1157.6,-277.05 1164.75,-262.76 1170.23,-251.79"/>
</g>
<!-- minimalism -->
<g id="node22" class="node">
<title>minimalism</title>
<ellipse fill="none" stroke="black" cx="1188.63" cy="-378" rx="53.89" ry="18"/>
<text text-anchor="middle" x="1188.63" y="-374.3" font-family="Times,serif" font-size="14.00">minimalism</text>
</g>
<!-- minimalism&#45;&#45;self&#45;reference -->
<g id="edge34" class="edge">
<title>minimalism&#45;&#45;self&#45;reference</title>
<path fill="none" stroke="black" d="M1177.74,-360.05C1170.66,-349.05 1161.48,-334.76 1154.42,-323.79"/>
</g>
<!-- minimalism&#45;&#45;recursion -->
<g id="edge35" class="edge">
<title>minimalism&#45;&#45;recursion</title>
<path fill="none" stroke="black" d="M1198.36,-360.2C1207.5,-342.25 1218.78,-313.01 1211.63,-288 1207.81,-274.66 1199.56,-261.41 1192.27,-251.5"/>
</g>
<!-- isomorphism -->
<g id="node24" class="node">
<title>isomorphism</title>
<ellipse fill="none" stroke="black" cx="1181.63" cy="-162" rx="57.69" ry="18"/>
<text text-anchor="middle" x="1181.63" y="-158.3" font-family="Times,serif" font-size="14.00">isomorphism</text>
</g>
<!-- minimalism&#45;&#45;isomorphism -->
<g id="edge36" class="edge">
<title>minimalism&#45;&#45;isomorphism</title>
<path fill="none" stroke="black" d="M1200.07,-360.13C1218.76,-330.35 1251.82,-266.82 1231.63,-216 1225.79,-201.3 1213.73,-188.32 1202.92,-178.89"/>
</g>
<!-- recursion&#45;&#45;isomorphism -->
<g id="edge33" class="edge">
<title>recursion&#45;&#45;isomorphism</title>
<path fill="none" stroke="black" d="M1179.37,-215.7C1179.84,-204.85 1180.43,-190.92 1180.9,-180.1"/>
</g>
<!-- acoustic ecology -->
<g id="node25" class="node">
<title>acoustic ecology</title>
<ellipse fill="none" stroke="black" cx="510.63" cy="-450" rx="69.59" ry="18"/>
<text text-anchor="middle" x="510.63" y="-446.3" font-family="Times,serif" font-size="14.00">acoustic ecology</text>
</g>
<!-- acoustic ecology&#45;&#45;listening -->
<g id="edge37" class="edge">
<title>acoustic ecology&#45;&#45;listening</title>
<path fill="none" stroke="black" d="M544.77,-434.15C574.13,-421.39 615.95,-403.21 643.43,-391.26"/>
</g>
<!-- acoustic ecology&#45;&#45;attention -->
<g id="edge38" class="edge">
<title>acoustic ecology&#45;&#45;attention</title>
<path fill="none" stroke="black" d="M508.26,-431.55C504.92,-400.3 502.01,-333.79 529.63,-288 540.78,-269.52 561.12,-255.93 578.1,-247.15"/>
</g>
<!-- acoustic ecology&#45;&#45;ambience -->
<g id="edge39" class="edge">
<title>acoustic ecology&#45;&#45;ambience</title>
<path fill="none" stroke="black" d="M461.64,-437.15C426.03,-428.39 376.71,-415.96 333.63,-404 317.53,-399.53 299.79,-394.24 284.86,-389.68"/>
</g>
<!-- acoustic ecology&#45;&#45;soft fascinations -->
<g id="edge40" class="edge">
<title>acoustic ecology&#45;&#45;soft fascinations</title>
<path fill="none" stroke="black" d="M463.42,-436.64C437.61,-428.97 405.51,-417.91 378.63,-404 334.25,-381.03 288.29,-344.47 263.41,-323.41"/>
</g>
</g>
</svg>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.12/plans </div>
  </div>
  <div class="entry-content">
  <h2><a href="/plans/resynth">resynth</a></h2>
  <!--<div class="meta"></div>-->




  <p>how to work just with sounds in environment? idea for a resynth by upstairs neighbor and composer <a href="https://www.pablogarreton.com/">pablo garreton</a>.</p>
<p>integrate resynth for drone from impulse<br />
  - look into pd fft analysis and resynthesis<br />
  - found working example of fft filter on [pd-tutorial.com] (http://www.pd-tutorial.com/german/ch03s08.html)<br />
  - <a href="{filename}/experiments/fft-filter">a filter to fight with</a> emerges</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.07/records | St. Michaels, Brüsselerplatz</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/orgelstunde">Orgelstunde</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-07-07_BruesselerPlatzOrgel_1.mp3"></div>
        <div class="sf" id="2020-07-07_BruesselerPlatzOrgel_3.mp3"></div>
        <video src="/media/2020-07-07_191631.mp4#vertical" controls></video>
        <video src="/media/2020-07-07_185128.mp4" controls></video>

  <p>A serendipitous organ hour at the St. Michaels church in Brüsseler Platz. Standing in the middle of the church, kids play outside, filter through, reverberate. Victor switches the organ on, a low hum, a deep breath fills the space. Soft flutes tumble in, strings and bass sounds smoothly drift into eachother.</p>
<p>Victor invites us upstairs for an organ hour with the <em>Baroque Synthesizer</em>, displaying the voice options assigned to three keyboards, foot pedals, volume pedal, flexible coupling.</p>
<p>for next time:</p>
<ul>
<li>try a two stereo-mic setup:<ul>
<li>in front of organ (in player's position) to capture wide stereo image</li>
<li>in middle of church, for reverb, outside sound, trumpet</li>
</ul>
</li>
<li>felix free to move around the space with trumpet</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.07.04/meta </div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/emergence-in-audibly-structured-soundscape">Emergence in audibly-structured soundscape</a></h2>
  <!--<div class="meta"></div>-->




  <?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Title: emergence Pages: 1 -->
<svg width="491pt" height="104pt"
 viewBox="0.00 0.00 490.76 103.58" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 99.58)">
<title>emergence</title>
<!-- audiosystem -->
<g id="node1" class="node">
<title>audiosystem</title>
<ellipse fill="none" stroke="black" cx="55.25" cy="-64" rx="55.49" ry="18"/>
<text text-anchor="middle" x="55.25" y="-60.3" font-family="Times,serif" font-size="14.00">audiosystem</text>
</g>
<!-- imprint in space -->
<g id="node2" class="node">
<title>imprint in space</title>
<ellipse fill="none" stroke="black" cx="214.73" cy="-64" rx="68.49" ry="18"/>
<text text-anchor="middle" x="214.73" y="-60.3" font-family="Times,serif" font-size="14.00">imprint in space</text>
</g>
<!-- audiosystem&#45;&gt;imprint in space -->
<g id="edge1" class="edge">
<title>audiosystem&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M110.89,-64C119.12,-64 127.75,-64 136.35,-64"/>
<polygon fill="black" stroke="black" points="136.42,-67.5 146.42,-64 136.42,-60.5 136.42,-67.5"/>
</g>
<!-- field recorder -->
<g id="node4" class="node">
<title>field recorder</title>
<ellipse fill="none" stroke="black" cx="400.87" cy="-18" rx="57.69" ry="18"/>
<text text-anchor="middle" x="400.87" y="-14.3" font-family="Times,serif" font-size="14.00">field recorder</text>
</g>
<!-- audiosystem&#45;&gt;field recorder -->
<g id="edge5" class="edge">
<title>audiosystem&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M93.56,-50.86C109.65,-45.71 128.8,-40.27 146.49,-37 208.99,-25.45 281.39,-20.88 332.76,-19.1"/>
<polygon fill="black" stroke="black" points="333.18,-22.58 343.07,-18.76 332.96,-15.59 333.18,-22.58"/>
</g>
<!-- perciever&#45;performer -->
<g id="node3" class="node">
<title>perciever&#45;performer</title>
<ellipse fill="none" stroke="black" cx="400.87" cy="-72" rx="81.79" ry="18"/>
<text text-anchor="middle" x="400.87" y="-68.3" font-family="Times,serif" font-size="14.00">perciever&#45;performer</text>
</g>
<!-- imprint in space&#45;&gt;perciever&#45;performer -->
<g id="edge2" class="edge">
<title>imprint in space&#45;&gt;perciever&#45;performer</title>
<path fill="none" stroke="black" d="M281.69,-60.36C294.52,-60.67 308.09,-61.2 321.27,-61.9"/>
<polygon fill="black" stroke="black" points="321.09,-65.39 331.27,-62.47 321.48,-58.41 321.09,-65.39"/>
</g>
<!-- imprint in space&#45;&gt;field recorder -->
<g id="edge6" class="edge">
<title>imprint in space&#45;&gt;field recorder</title>
<path fill="none" stroke="black" d="M265.08,-51.67C289.81,-45.49 319.83,-37.99 345.26,-31.64"/>
<polygon fill="black" stroke="black" points="346.26,-35 355.12,-29.18 344.57,-28.21 346.26,-35"/>
</g>
<!-- perciever&#45;performer&#45;&gt;audiosystem -->
<g id="edge3" class="edge">
<title>perciever&#45;performer&#45;&gt;audiosystem</title>
<path fill="none" stroke="black" d="M339.45,-83.96C287.95,-92.39 212.07,-100.6 146.49,-91 131.91,-88.87 116.41,-84.89 102.44,-80.63"/>
<polygon fill="black" stroke="black" points="103.17,-77.19 92.58,-77.5 101.05,-83.86 103.17,-77.19"/>
</g>
<!-- perciever&#45;performer&#45;&gt;imprint in space -->
<g id="edge4" class="edge">
<title>perciever&#45;performer&#45;&gt;imprint in space</title>
<path fill="none" stroke="black" d="M320.3,-75.24C308.34,-74.82 296.09,-74.25 284.38,-73.53"/>
<polygon fill="black" stroke="black" points="284.45,-70.03 274.25,-72.88 284,-77.02 284.45,-70.03"/>
</g>
</g>
</svg>

<p><em>Figure: Emergence in place-language improvisation</em></p>
<p>Understanding emergent sound structures as macroforms emerging from interactions of the microforms.</p>
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Title: macroform_from_microform Pages: 1 -->
<svg width="343pt" height="279pt"
 viewBox="0.00 0.00 342.89 279.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 275)">
<title>macroform_from_microform</title>
<g id="clust2" class="cluster">
<title>cluster_0</title>
<path fill="transparent" stroke="black" stroke-dasharray="1,5" d="M183.89,-8C183.89,-8 314.89,-8 314.89,-8 320.89,-8 326.89,-14 326.89,-20 326.89,-20 326.89,-215 326.89,-215 326.89,-221 320.89,-227 314.89,-227 314.89,-227 183.89,-227 183.89,-227 177.89,-227 171.89,-221 171.89,-215 171.89,-215 171.89,-20 171.89,-20 171.89,-14 177.89,-8 183.89,-8"/>
<text text-anchor="middle" x="249.39" y="-211.8" font-family="Times,serif" font-size="14.00">real&#45;time audio processor</text>
</g>
<!-- space -->
<g id="node1" class="node">
<title>space</title>
<ellipse fill="none" stroke="black" cx="145.89" cy="-253" rx="30.59" ry="18"/>
<text text-anchor="middle" x="145.89" y="-249.3" font-family="Times,serif" font-size="14.00">space</text>
</g>
<!-- perciever&#45;performer -->
<g id="node2" class="node">
<title>perciever&#45;performer</title>
<ellipse fill="none" stroke="black" cx="81.89" cy="-178" rx="81.79" ry="18"/>
<text text-anchor="middle" x="81.89" y="-174.3" font-family="Times,serif" font-size="14.00">perciever&#45;performer</text>
</g>
<!-- space&#45;&gt;perciever&#45;performer -->
<g id="edge1" class="edge">
<title>space&#45;&gt;perciever&#45;performer</title>
<path fill="none" stroke="black" d="M128.09,-237.92C118.4,-228.32 106.69,-215.34 97.37,-204.01"/>
<polygon fill="black" stroke="black" points="100.05,-201.75 91.08,-196.12 94.58,-206.12 100.05,-201.75"/>
</g>
<!-- input -->
<g id="node3" class="node">
<title>input</title>
<ellipse fill="none" stroke="black" cx="209.89" cy="-178" rx="28.7" ry="18"/>
<text text-anchor="middle" x="209.89" y="-174.3" font-family="Times,serif" font-size="14.00">input</text>
</g>
<!-- space&#45;&gt;input -->
<g id="edge2" class="edge">
<title>space&#45;&gt;input</title>
<path fill="none" stroke="black" d="M162.31,-237.62C165.91,-234.24 169.62,-230.58 172.89,-227 179.77,-219.47 186.75,-210.76 192.76,-202.84"/>
<polygon fill="black" stroke="black" points="195.69,-204.77 198.85,-194.66 190.07,-200.59 195.69,-204.77"/>
</g>
<!-- perciever&#45;performer&#45;&gt;space -->
<g id="edge4" class="edge">
<title>perciever&#45;performer&#45;&gt;space</title>
<path fill="none" stroke="black" d="M102.11,-195.5C111.41,-204.91 122.14,-216.9 130.75,-227.4"/>
<polygon fill="black" stroke="black" points="128.17,-229.78 137.13,-235.44 133.65,-225.43 128.17,-229.78"/>
</g>
<!-- perciever&#45;performer&#45;&gt;input -->
<g id="edge3" class="edge">
<title>perciever&#45;performer&#45;&gt;input</title>
<path fill="none" stroke="black" d="M163.89,-178C166.23,-178 168.56,-178 170.9,-178"/>
<polygon fill="black" stroke="black" points="171.14,-181.5 181.14,-178 171.14,-174.5 171.14,-181.5"/>
</g>
<!-- process -->
<g id="node4" class="node">
<title>process</title>
<ellipse fill="none" stroke="black" cx="216.89" cy="-106" rx="37.09" ry="18"/>
<text text-anchor="middle" x="216.89" y="-102.3" font-family="Times,serif" font-size="14.00">process</text>
</g>
<!-- input&#45;&gt;process -->
<g id="edge5" class="edge">
<title>input&#45;&gt;process</title>
<path fill="none" stroke="black" d="M211.62,-159.7C212.39,-151.98 213.32,-142.71 214.18,-134.11"/>
<polygon fill="black" stroke="black" points="217.67,-134.4 215.18,-124.1 210.7,-133.71 217.67,-134.4"/>
</g>
<!-- output -->
<g id="node5" class="node">
<title>output</title>
<ellipse fill="none" stroke="black" cx="248.89" cy="-34" rx="33.29" ry="18"/>
<text text-anchor="middle" x="248.89" y="-30.3" font-family="Times,serif" font-size="14.00">output</text>
</g>
<!-- process&#45;&gt;output -->
<g id="edge6" class="edge">
<title>process&#45;&gt;output</title>
<path fill="none" stroke="black" d="M224.64,-88.05C228.33,-79.97 232.84,-70.12 236.96,-61.11"/>
<polygon fill="black" stroke="black" points="240.24,-62.34 241.22,-51.79 233.88,-59.43 240.24,-62.34"/>
</g>
<!-- output&#45;&gt;space -->
<g id="edge7" class="edge">
<title>output&#45;&gt;space</title>
<path fill="none" stroke="black" d="M255.3,-51.74C268.24,-88.67 292.61,-177.78 247.89,-227 239.43,-236.31 210.46,-242.85 185.54,-246.9"/>
<polygon fill="black" stroke="black" points="184.89,-243.45 175.54,-248.43 185.95,-250.37 184.89,-243.45"/>
</g>
</g>
</svg>

<p><em>Figure: Emergent macroform from microform interaction</em></p>
<p>A real-time composition, to let "the musical (macro-level) structure emerge from sound itself and its internal organization (micro-level)." <sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<p>Resonating with selections from <em>Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music</em> (Renaud Meric, Makis Solomos)<sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">1</a></sup> :</p>
<blockquote>
<p>While composing with an ecosystemic approach, the composer creates an audio system that interacts with the environment (i.e. space). This space, in which and from which music emerges, is also the listener’s space. Thus what emerges is the result of a confrontation between the listener’s cognitive system and the audio system used in the musical work. The emergent sound is difficult to define: its general outline is unpredictable and unstable; it is dependent on a dynamic musical space, which is constructed by active listening and an active audio system simultaneously.</p>
<p>focusing on the ephemeral moment in which music emerges in the interaction between the listener and the product of the audio system inside a specific space.</p>
<p>in reality, we don’t listen to sound but to its own “imprint” (empreinte), in the sense of the word developed by Georges Didi-Huberman (2008).</p>
<p>in his own music, Di Scipio opted for complex dynamic systems: “Chaos and the dynamics of complex systems, as accessible with iterated numerical processes, represented for me a way to compose small sonic units such that a higher-level sonority would manifest itself in the process” (Di Scipio inAnderson, 2005)</p>
<p>In one of his first articles (Di Scipio, 1994), he elaborated a “theory of sonological emergence”, whereby form (macroform) is viewed as “a process of timbre formation” (Di Scipio, 1994: 205)</p>
<p>The idea of emergent sound structures is related to the elaboration of a sub-symbolic theory. In the “theory of sonological emergence”, the emergence of a higher level should happen through grains and samples, neither of which are symbols, as they are located on a low level (cf. Di Scipio, 1994: 207). With composed interactions (cf. infra), Di Scipio puts the interaction at the signal level: all the information exchanges have a sonic nature (cf. Di Scipio, 2003: 272). We can draw a parallel between this strategy and the model of emergence in cognitive science. To the question “What is cognition?” the “computationalist” model answers “Data processing: the manipulation of symbols from rules” (Varela, 1996: 42), while the emergence model answers “The emergence of global states in a network of simple components” (Varela, 1996: 77). Regarding music, the issue at stake here is as follows: if we want the higher level (the macroform) to appear as an emergence and not as an independent construction, we have to work only at the lower level, abandoning the intermediate level, which is the level of symbols.</p>
<p>According to emergence theory, the emergence of sound structures is possible because of the fact that the composer develops systems (in the sense of cybernetics) close to living systems, which are characterized by their capacity for auto-organization</p>
</blockquote>
<p>Whilst not directly applicable (much of the recordings of free play references past melodies played and familiar intervals), it speaks to an attitude of openness and responsiveness in dialogue with the current situation and other players through which the musical moment emerges.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p><a href="https://hal.archives-ouvertes.fr/hal-01202885/document">Renaud Meric, Makis Solomos: Analysing Audible Ecosystems and Emergent Sound Structures in DiScipio’s Music</a>&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.27/meta </div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/inspiration-from-tim-shaw">inspiration from tim shaw</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-06-27_211535_mb-fan.ogg"></div>

  <p>resonating while listening to <a href="https://www.mixcloud.com/resonanceextra/the-field-recording-show-8-wandering-sunday-14th-june-2020/">tim shaw on listening and field recording</a></p>
<p>Tim Shaw, on indeterminancy and uncertainty in field recording and soundwalks, finds environmental sound, much richer to practice responding to specific sites/themes outside of studio. Listening being the key practice of the work.</p>
<p>Field recording not as a documentary of one place to another, more as a live, performative act. Whereas traditionally it might be understood as: go somewhere with mics, sit, press record, bring it back to studio, edit/layer... the performative aspect of walking to the site, setting up, these gestures aren't visible. There's a dislocation between making and presentation. How to fold together?</p>
<p>Recording, composing, improvising with the soundscapes that move through.</p>
<p>Normally, recordings are deleted at the end of the walks. Flatten presentation and process, all mistakes like handling noise.</p>
<p>Headphones allow dynamics to come-in - is it sounding in the world outside or it is processed through? Starting with omni-directional mics, then take recordings using contact/hydro/electromic.</p>
<p>The system is malleable and shifting, like the soundscape, always shifting and indeterminate.</p>
<p>Always tries to carry a recorder, decides to start when something catches interest, finding resonant spaces, or attaching a contact mic. Starts by walking and seeking with the ear and eye.</p>
<p>How long to let the recorder roll for is question of composition in itself.</p>
<p>Not about archiving, possesion, but about the process, and the making and the act of it is often more interesting than the recording itself. Using this process to learn the space, how does it react? So it's expansive - what are the possibilites, in the most holistic way?</p>
<p>Not going into a space with too many ideas, being open to the unpredictability, allowing those unexpected events to be just as meaningful as those planned.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.26/records | <a href="/ul/">ul</a>   | p17</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/mnmlma">mnmlma</a></h2>
  <!--<div class="meta">  <a href="/ul/">ul</a>  </div>-->



        <div class="sf" id="2020-06-26_141933_ma-iphone-piano.ogg"></div>
        <div class="sf" id="2020-06-26_170559_mnml-ma-piano-2.ogg"></div>

  <p>testing the patch running running simply on iphone using built-in mic. the lightness and lack of cable connections afford an intuitive movement of the integrated mic as dry/wet modulation.</p>
<pre><code>tapeshift~ = pitch -12, window ~100, delay ~100
process = adc~:tapeshift~:dac~
</code></pre>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.25/records | <a href="/ul/">ul</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/feedback-matrix">feedback matrix</a></h2>
  <!--<div class="meta">  <a href="/ul/">ul</a>  </div>-->



        <div class="sf" id="2020-06-24_110512_feedback-1.ogg"></div>
        <div class="sf" id="2020-06-24_110956_feedback-2.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.24/meta </div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/field-recording">field recording</a></h2>
  <!--<div class="meta"></div>-->




  <p>if the project seems broad, scattered, loosely organized, and unfocused, that's because it is. but one crucial theme is the experience of making-in-real-time, acting and reacting in a live way.</p>
<p>the records then are soundscapes of a "genuine but ephemeral set of circumstances existing in a precise moment of time," rather than soundscapes "meticulously fabricated and controlled in the vacuum of an audio editor".<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup></p>
<blockquote>
<p>actual events from a specific time and place ... a moment’s explicit actuality and serendipitous fragility. (Swift 8)</p>
<p>... a soundscape is not simply a sum of all these sounds; rather it is a particular subset filtered through the context of a given environmental condition (Swift 6)</p>
</blockquote>
<p>Curiously, wishing to capture these events often blocks these events from occurring. This could be an example of the observer effect, a "common phenomenon where the act of observation can alter the situation being observed." (Swift 3) Perhaps the psychic attention to recording takes valuable attention away from the actual act, a moment of flow, a sort of reset.</p>
<p>Oft noticed is autotelic free play on an instrument -&gt; maybe a moment, groove, emerges - though to capture this! -&gt; stop playing, set up recorder, try to find it again, takes some time, energy is distracted, and the recording then captures this difference and distraction, not the original moment of free play and discovery.</p>
<p>Several strategies to deal with this have been considered:</p>
<ul>
<li>a recorder handy and ready to start at the click of a button (requiring minimal attention)</li>
<li>a recorder always running</li>
<li>a buffer recorder (capturing the last x-seconds, after the fact)</li>
</ul>
<p>Setting these to run still requires some forethought, whereas the moments occur seemingly unexpectedly/unpredictably, and most notably while not recording. A possible possible solution is to intrinsically integrate the recorder into the sound ecosystem so that recording is a seamless act with listening while using the system.</p>
<p>as an aside, the work is about sounds situated in spaces. &gt; One of Bernie Krause's tenets is that sounds should experienced in the context of their environment rather than attempting to isolate the sound. (Swift 10)</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Swift&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.23/modules/archive </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/archive/inverting-images-pd-screenshots">inverting images (pd screenshots)</a></h2>
  <!--<div class="meta"></div>-->




  <p>tiny markup in markdown allows for easy client-side image-inverting</p>
<p>CSS:</p>
<pre><code class="css">img[src$='#pd-screenshot'] {
  filter: invert();
  mix-blend-mode: screen;
}
</code></pre>

<p>Markdown:</p>
<pre><code class="markdown">![alt]({static}/patches/demo.pd.png#pd-screenshot)
</code></pre>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.20/modules/archive </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/archive/managing-recordings">managing recordings</a></h2>
  <!--<div class="meta"></div>-->




  <p>Generally, the archive/annotator displays a light, web-friendly version of the files for viewing, with the originals stored elsewhere, as the raw files quickly fill up storage space.</p>
<p>The files are timestamped with their creation date (YYYY-MM-DD_HHMMSS.*) to enable easy sorting and individuality and reinforce that they were created at that time and not edited afterwards.</p>
<h3>scripts</h3>
<p>a collection of file managment bash scripts, meant to be run in a folder of raw files. requires <a href="">ffmpeg</a>.</p>
<p><a href="/scripts/wav-to-mp3.sh">wav-to-mp3.sh</a><br />
renames *.wav to file creation timestamp and compresses to mp3, returns list of mp3 files</p>
<p><a href="/scripts/mov-to-mp4.sh">mov-to-mp4.sh</a><br />
renames *.mov to file creation timestamp and compresses to mp4, returns list of mp4 files</p>
<p><a href="/scripts/jpg-to-web.sh">jpg-to-web.sh</a><br />
renames *.jpg to file created timestamp, compresses and resizes jpg images for web, returns list of jpg files</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.20/records | <a href="/field-recording/">field recording</a>   | Allgäu</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/walking-down">walking down</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->



        <div class="sf" id="2020-06-20_084248.ogg"></div>
        <div class="sf" id="2020-06-20_084248[vm].ogg"></div>
        <div class="sf" id="2020-06-20_084726.ogg"></div>
        <div class="sf" id="2020-06-20_090718.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.19/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/5d-routing-matrix">5D routing matrix</a></h2>
  <!--<div class="meta"></div>-->




  <p>A 5D routing matrix for PD affords programatic/instruction-based access to conduct signal routing on-the-fly with variable destinations, fade-time, and scheduling (wait x-ms first).</p>
<p>Syntax:</p>
<pre><code>[; route &lt;out&gt; &lt;in&gt; &lt;value&gt; &lt;ms-to-fade&gt; &lt;ms-to-wait&gt;(
</code></pre>

<p>This effectively decouples the patching interface from the PD GUI, allowing control to be given to, ie., the MobMuPLat touchscreen interface, which implements a grid control and 3 sliders (value, ms-to-fade, ms-to-wait).</p>
<p>This also exposes the potential for live-coding/text-based triggering, ie:</p>
<pre><code>[x]
|
[metro 100]
|
[; route &lt;dac~&gt; &lt;adc~ 1&gt; 1 10 0; r &lt;dac~&gt; &lt;adc~ 1&gt; 0 10 20(
[x]
|
[metro 101]
|
[; route &lt;dac~&gt; &lt;adc~ 2&gt; 1 10 0; r &lt;dac~&gt; &lt;adc~ 2&gt; 0 10 20(
</code></pre>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.19/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/buffer-looper">buffer looper</a></h2>
  <!--<div class="meta"></div>-->




  <ul>
<li>[ ] document</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.19/records | <a href="/field-recording/">field recording</a>   | allgäu</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/in-the-rain">in the rain</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->


  <img src="/media/2020-06-19_195715.jpg">

        <div class="sf" id="2020-06-19_1939.ogg"></div>
        <div class="sf" id="2020-06-19_1954.ogg"></div>

  <p><img alt="rain setup" src="/media/2020-06-19_183336.jpg" /></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.18/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/allgau">allgäu</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->


  <img src="/media/2020-06-17_093758.jpg">

        <div class="sf" id="2020-06-18_1124.ogg"></div>
        <div class="sf" id="2020-06-18_1232.ogg"></div>
        <div class="sf" id="2020-06-18_1233.ogg"></div>
        <div class="sf" id="2020-06-18_1238.ogg"></div>
        <div class="sf" id="2020-06-18_1240.ogg"></div>
        <div class="sf" id="2020-06-18_1701.ogg"></div>
        <div class="sf" id="2020-06-18_1805.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.18/meta | allgaü</div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/archiving-process">archiving process</a></h2>
  <!--<div class="meta"></div>-->




  <p>(voice memo transcription, need to clean)</p>
<p>the archiving process is to have the original raw file, with maybe some markers at the beginning fo the file to talk in what the context of the thing is (first section is meta description). to audition, drop it into a folder that compresses the original file, drops the original onto a hard drive. and it's available for audition in the annotator. layers to configure/toggle:</p>
<p>-timestamp<br />
-place<br />
-mark points of time/regions<br />
    -tag/make notes on these markers</p>
<p>That's an annotation added in the process of reviewing. In the process of making/creating the moment you can easily make a marker or start and end a region, which saves some time, then when listening back you already have a place to start watching/listening.</p>
<p>In addition to the manually entered annotation, any interactions with the patches are logged with a line which is the information-preserved-transformation of that interaction. so the interaction is say: route the mic to the speaker, fade up in 10 secs to 50%, do that in first in 5 seconds. this is a simple single line instruction, and this is written down in that way, possibly also as a human-readable, possibly easy to type, format. and this is saved as a log file and can also be toggled, shown on and off in the annotations.</p>
<p>the benefit of also keeping track of all these digital interactions as instructions is one has the easy possibility to change later. what would have happen if we didn't trigger this? so you can remix it later by running it through the patch again, in real time, in this case loading the original file.</p>
<p>the patch saves three files:<br />
-text file: log and annotations<br />
-sound: raw, straight from the microphone<br />
-sound: from patch, exactly what's sent to speakers</p>
<p>with the first two elements, we can recreate the third file, from the list of log instructions. then it can be revisited.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.18/plans | allgäu</div>
  </div>
  <div class="entry-content">
  <h2><a href="/plans/transcribed-from-pocketbook">transcribed from pocketbook</a></h2>
  <!--<div class="meta"></div>-->




  <p>transcribed from pocketbook in reverse chronological order</p>
<ul>
<li>[x] 5D routing matrix<ul>
<li>on the fly routing patching control</li>
<li>log of interactions affords easy real-time scripting interface<ul>
<li>'limiter' of too much clipping could undo last interaction from log?<ul>
<li>although this only works if feedback was caused by digital interaction, not change to audio in</li>
<li>sequencer interface for phone</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>stopping at the places in between</li>
<li>walking soundscape<ul>
<li>footstep rhythm</li>
<li>car drone<ul>
<li>how to work with?</li>
</ul>
</li>
</ul>
</li>
<li>[x] make marker in patch</li>
<li>pd log</li>
<li>ma - empty containers</li>
<li>rhythmic moving playheads<ul>
<li>how to deal with clicks?<ul>
<li>[x] pd-smoother (envelope)</li>
</ul>
</li>
</ul>
</li>
<li>buffer recorder recalls ephemeral moments</li>
<li>moving image as lo-fi sound processor/convolver</li>
<li>ultralight setup<ul>
<li>[x] pd x mobmuplat</li>
</ul>
</li>
<li>diffusion and routing as percussion (ambisonic/further away/filtered)</li>
<li>emergence in gifs, live-arppegio-code</li>
<li>emergence on the border of control</li>
<li>sound object delay line... blurring figure-ground by delaying figure-ground<ul>
<li>[x]</li>
<li>delayline changing speed can be octave/interval</li>
<li>moving delayline as rhythmic/textural harmonizer</li>
<li>gesture -&gt; rhythmic delay texture</li>
<li>slow gestures as play with space/time</li>
<li>texture from multiple delay lines,</li>
<li>delay line, listening again</li>
<li>when changing delay line length, fade it out / have variable gain</li>
</ul>
</li>
<li>environmental music: amplifying/using what is already there<ul>
<li>attention restoration theory</li>
<li>walk every day</li>
</ul>
</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.16/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/train-to-allgau">train to allgäu</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-16_0133.ogg"></div>

  <p><img alt="pd in the train" src="/media/2020-06-16_083333.jpg" /></p>
<p>a space in-between, a space on the way. mediating the loud train ride through a macbook microphone and earlier piano sample to test functionality of the patch accidentally re-situates the listening experience as active and real-time.</p>
<blockquote>
<p>the presence of everything, nothing shouts importance ... quiet is quieting ... (Gordon Hempten)</p>
</blockquote>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.14/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/ginsterpfad-ambience">ginsterpfad ambience</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->



        <div class="sf" id="2020-06-14_2055_ginsterpfad-ambience.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.14/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/routing-matrix-pt-2">routing matrix pt. 2</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-14_0939.ogg"></div>
        <div class="sf" id="2020-06-14_0959.ogg"></div>
        <div class="sf" id="2020-06-14_1022.ogg"></div>
        <div class="sf" id="2020-06-14_1306.ogg"></div>

  <p>in situ slow-evolving conducting/scheduling</p>
<p>first thing in the morning, open up the routing-matrix patch from yesterday, pull in a looped piano recording.</p>
<p>filtered in feedback and filtered again.</p>
<pre><code>route tapeshift~:dac~ 1 10000
X
|
metro 125
|
route sf~:dac~ 1 0; route sf~:dac~ 0 0 10
</code></pre>

<p><a href="/patches/routing-matrix/routing-matrix.pd">patch.pd</a></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.13/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/routing-matrix">routing matrix</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-13_1305.ogg"></div>
        <div class="sf" id="2020-06-13_1308.ogg"></div>
        <div class="sf" id="2020-06-13_1317.ogg"></div>
        <div class="sf" id="2020-06-13_1318.ogg"></div>
        <div class="sf" id="2020-06-13_1322.ogg"></div>
        <div class="sf" id="2020-06-13_1642.ogg"></div>
        <div class="sf" id="2020-06-13_1805_stadtwald-crickets.ogg"></div>
        <div class="sf" id="2020-06-13_2042.ogg"></div>
        <div class="sf" id="2020-06-13_2101.ogg"></div>

  <p>routing matrix with variable fade-time working</p>
<p><a href="/patches/routing-matrix/routing-matrix.pd">patch.pd</a></p>
<p>recordings feature prominent low-end ambience from traffic - how to use this? filter it out?</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.12/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/wassermannsee">Wassermannsee</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->



        <div class="sf" id="2020-06-12_1119.ogg"></div>
        <div class="sf" id="2020-06-12_1128.ogg"></div>
        <div class="sf" id="2020-06-12_1856.ogg"></div>
        <div class="sf" id="2020-06-12_2034_Wassermannsee.ogg"></div>

  <p>wind through reeds, loud ducks. off-recorder mics make cue-making (almost) silent.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.11/records | <a href="/field-recording/">field recording</a>   | Ginsterpfad</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/am-ginsterpfad">Am Ginsterpfad</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->



        <div class="sf" id="2020-06-11_2036.ogg"></div>
        <div class="sf" id="2020-06-11_2049.ogg"></div>
        <div class="sf" id="2020-06-11_2131.ogg"></div>
        <div class="sf" id="2020-06-12_1856.ogg"></div>

  <p>walking soundscape, slowly-changing filters as attention-prompts. elements:</p>
<ul>
<li>footstep rhythm</li>
<li>how to deal with traffic drone?</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.11/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/pd-in-the-park">pd in the park</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-11_2140.ogg"></div>

  <p>how to work with droning car sounds? trying to reinforce/mask them with sinewave organ.</p>
<p><img alt="pd in the park screenshot" src="/patches/2020-06-11_2140_pd-in-the-park.pd.png#pd-screenshot" /></p>
<p><a href="/patches/2020-06-11_2140_pd-in-the-park.pd">pd in the park patch</a></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.09/records | <a href="/pd/">pd</a>   | p17</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/buffergrid-looper-piano">buffer/grid looper, piano</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-09_121053.ogg"></div>
        <div class="sf" id="2020-06-09_2352.mov"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.07/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/ppgrainer-t03-organ">[pp.grainer~] T03 organ</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-07_122700.ogg"></div>
        <div class="sf" id="2020-06-07_1356.ogg"></div>
        <div class="sf" id="2020-06-07_145600.ogg"></div>
        <div class="sf" id="2020-06-07_194200_grainer-vox-test.ogg"></div>

  <p>testing sequencer with pp.grainer~ and KHG organ sample</p>
<pre><code>process=khg-organ.wav:pp.grainer~
</code></pre>

<pre><code>[pp.grainer~]&lt;:([tapeshift~].[pan~].[fade~],2)
</code></pre>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.06/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/g01">G01</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-06_211452.ogg"></div>

  <p>ma jumps on piano loops</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.06/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/ma-jumper">ma-jumper</a></h2>
  <!--<div class="meta"></div>-->




  <ul>
<li>[ ] document</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.06/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/pd-smoother-t01">[pd smoother] T01</a></h2>
  <!--<div class="meta"></div>-->



        <div class="sf" id="2020-06-06_215730.ogg"></div>

  <p>[pd smoother] handles timing for fading level to zero while changing playPos</p>
<p><img alt="screenshot of pd-smoother" src="/patches/2020-06-06_smoother.pd.png#pd-screenshot" /></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.06.05/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/2020-06-05_102557">2020-06-05_102557</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-05_102557.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.06.04/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/2020-06-04_221410">2020-06-04_221410</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-06-04_221410.ogg"></div>

  <p>patch notes: two asynchronous loops, one ma loop</p>
<p>tapeshift~ delay on live input</p>
<p>would be nice: easy control of tapeshift~ volume (at least)</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.30/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/krupp-gm7-and-the-dogs-outside">krupp gm7 and the dogs outside</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-05-30_142454.mp3"></div>

  <p>testing chord with rhymthic 1/8 playpos jumping as carpet</p>
<p>listened through through schmalfußs tape-IR. consider feeding through, re-recording?</p>
<p>todo: add playpos-jumping module</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.25/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/2020-05-25_175236">2020-05-25_175236</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-05-25_175236.ogg"></div>

  <p>past sound as rhythmic pulse</p>
<p>spring between random segments of the loop</p>
<pre><code>every 1/8, jumping 1/8*lengthOfLoop * random(8)
</code></pre>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.22/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/2020-05-22_174851">2020-05-22_174851</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-05-22_174851.ogg"></div>

  <p>1 mic in room with piano with loops and tapeshift</p>
<p>fix:</p>
<ul>
<li>[x] changing cycle length after buffer loop is made removes sound</li>
</ul>
<p>todo:</p>
<ul>
<li>[x] autogenerate meta.md</li>
<li>[x] include file automatically</li>
<li>[x] include date automatically</li>
<li>[ ] convert to mp3?</li>
<li>[x] offer voice memo feature? /</li>
<li>[ ] auto-open text editor with meta file?</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.20/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/buffer-looper-router">Buffer Looper-Router</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-05-20_1921.ogg"></div>

  <p>getting back to the launchpad-looper-router-interface, checking that it works as expected after a few days away. testing with a sample</p>
<p>patch notes: sample (taiwan-junglebirds.wav) looped, buffer looped, routed into tape-shift effect with feedback, starting to find something, hit record</p>
<p>todo:</p>
<ul>
<li>[x] get input routing working, so that can happen on the pad</li>
<li>[ ] get resonanant filter+tapeshift also mapped to pad buttons</li>
<li>[x] add record button to launchpad</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.18/modules </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/portable-sound-setup-options">portable sound setup options</a></h2>
  <!--<div class="meta"></div>-->




  <ul>
<li>field recorder with rich expressive convulution/mixing control layer</li>
<li>recorder with marker support</li>
<li>visual sonifier</li>
</ul>
<h3>hardware options</h3>
<h4>PiSound + Raspberry Pi</h4>
<p>components required:<br />
- RPI: 35€<br />
- PiSound: 99€<br />
- SD card: 10€<br />
- Battery</p>
<p>pros:<br />
  - dedicated device<br />
  - stereo audio in/out</p>
<p>explorations:<br />
  - [ ] document pisound explorations</p>
<p>findings:<br />
  - noisy preamp<br />
  - package is bulky and heavy</p>
<h4>Phone</h4>
<ul>
<li>iphone 5: 40€ (used)</li>
<li>otg cable: 20€</li>
<li>audio interface/field recorder: 60€</li>
</ul>
<p>decided to proceed with phone setup to reduce complexity, given the availability of MobMuPlat container app, and since it's a device most always carried around anyway.</p>
<h4>Bela Mini</h4>
<ul>
<li>Bela Mini: ~67€, bela.io</li>
<li>PocketBeagle-SC-569: 27€, mouser.de</li>
<li>MicroSD card: ____</li>
<li>Battery: _____ (3.3V)</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.14/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/khg-t02">KHG T02</a></h2>
  <!--<div class="meta"></div>-->


  <img src="/media/2020-05-14_161030.jpg">

        <div class="sf" id="2020-05-14_KHG-1.ogg"></div>
        <div class="sf" id="2020-05-14_KHG-3.ogg"></div>
        <div class="sf" id="2020-05-14_KHG-4.ogg"></div>
        <div class="sf" id="2020-05-14_KHG-5.ogg"></div>
        <div class="sf" id="2020-05-14_KHG-6.ogg"></div>
        <div class="sf" id="2020-05-14_KHG-8.ogg"></div>

  <p>Selected recorded improvisations from a sunny morning and afternoon in the Hl. Johannes XXIII church.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.11/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/buffer-looper-on-launchpad-d01">Buffer Looper on Launchpad D01</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-05-11_2200_P17.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.05.09/records | <a href="/visuals/">visuals</a>   | Stadtwald</div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/wind-on-grass">wind on grass</a></h2>
  <!--<div class="meta">  <a href="/visuals/">visuals</a>  </div>-->



        <video src="/media/2020-05-09_155011.mp4" controls></video>

  </div>

  <div class="entry-meta">
    <div class="date">2020.05.06/meta </div>
  </div>
  <div class="entry-content">
  <h2><a href="/meta/trying-to-get-organized">trying to get organized</a></h2>
  <!--<div class="meta"></div>-->




  <h3>Goals</h3>
<ul>
<li>Place Language - Tiny Place Poem</li>
<li>Emergence in interference patterns</li>
<li>noise studies</li>
<li>rhizomatic feedback loops</li>
<li>Feedback Dialogue</li>
<li>Feedback systems to inspire play</li>
<li>piano w thiago</li>
<li>mawamama</li>
<li>Realtime composition</li>
<li>Musical trance/flow contributor/actor</li>
<li>optimize experimentation - question unorganized/inefficient practice</li>
</ul>
<h3>Ideas</h3>
<ul>
<li>looper with decay (feedback through effect with adjustable dry/wet)</li>
<li>matrix/launchpad grid study with field-recorded/live sourced samples</li>
<li>recorder with easy marker maker</li>
</ul>
<h3>Method</h3>
<ul>
<li>[x] experiment, outside</li>
<li>phone setup</li>
<li>[x] otg cable</li>
<li>patch matrix?<ul>
<li>[x] python</li>
</ul>
</li>
<li>[x] mmp</li>
<li>go back to places</li>
<li>[x] organize notes &amp; recordings (maybe in blog-form)</li>
</ul>
<h3>challenges</h3>
<ul>
<li>noise pollution around NRW...</li>
<li>the paradox of willing spontaneity and preparing for emergence...</li>
</ul>
<h3>observations</h3>
<ul>
<li>slowness as generation method</li>
<li>aesthetics of places in between - soft fascinations: ripples, sunlight on leaves, wind in reeds, caustic reflections, connected to the journey to and from the place, forward movement</li>
</ul>
  </div>

  <div class="entry-meta">
    <div class="date">2020.05.03/records | <a href="/visuals/">visuals</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/on-screens">on screens</a></h2>
  <!--<div class="meta">  <a href="/visuals/">visuals</a>  </div>-->



        <video src="/media/2020-05-03_0147.mp4" controls></video>

  </div>

  <div class="entry-meta">
    <div class="date">2020.03.10/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/trainsketch-taiwan">Trainsketch Taiwan</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-03-10_171703_taiwan-trainsketch.ogg"></div>

  <p><img alt="taiwan-trainsketch screenshot" src="/patches/taiwan-trainsketch.png#pd-screenshot" /></p>
<p><a href="/patches/taiwan-trainsketch.pd">taiwan-trainsketch.pd</a></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.03.01/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/taiwan">Taiwan</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->




  <p><img alt="taiwan rock" src="/media/2020-03-01_1122_taiwan-rock.jpg" /></p>
<p>[todo] insert field recordings</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.02.15/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/trumpet-drone-in-wallraf-richartz-museum">Trumpet Drone in Wallraf-Richartz Museum</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-02-15_182316_felix-wallraf.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.02.14/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/crinkly-plastic-bag-water-sound">crinkly plastic bag -> water sound</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-02-14_200851_marie-plasticbag.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.02.05/records | <a href="/todo/">todo</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/mawamama-t01">mawamama t01</a></h2>
  <!--<div class="meta">  <a href="/todo/">todo</a>  </div>-->



        <div class="sf" id="2020-02-05_225924-mawamama-t01.ogg"></div>

  <p>first take of improvising in dialogue with an active figure-ground delayline modulation feedback. the length of a sound-object (distinguished as a ‘figure’) modulates the length of a delayline such that sounds made in a room are fed back to the room at varying–controllable–later times. pitch-shifting artefacts of the moving delayline abound.</p>
<p>with heiwa wong, marie stremmel, david martens</p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.02.02/records | <a href="/pd/">pd</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/sinepiano-drone">sine/piano drone</a></h2>
  <!--<div class="meta">  <a href="/pd/">pd</a>  </div>-->



        <div class="sf" id="2020-02-02_154031_sinedrone_1.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2020.01.23/modules/pd </div>
  </div>
  <div class="entry-content">
  <h2><a href="/modules/pd/figure-ground-delayline-modulator">Figure-Ground Delayline Modulator</a></h2>
  <!--<div class="meta"></div>-->




  <p>the length of a sound-object figure modulates the length of a delayline<br />
sounds received are fed back at varying, controllable, later times<br />
varying the change in speed pitches the sound being fed back</p>
<p>used in: mawamama t01</p>
<p><img alt="screenshot" src="/patches/figure-ground-delayline-modulator.pd.png#pd-screenshot" /><br />
<a href="/patches/figure-ground-delayline-modulator.pd">figure-ground-delayline-modulator.pd</a><br />
<a href="/patches/figure-ground-delayline-modulator-help.pd">figure-ground-delayline-modulator-help.pd</a></p>
  </div>

  <div class="entry-meta">
    <div class="date">2020.01.18/records | <a href="/visuals/">visuals</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/ginsterpfad-caustics">Ginsterpfad Caustics</a></h2>
  <!--<div class="meta">  <a href="/visuals/">visuals</a>  </div>-->



        <video src="/media/2020-01-18_142150.mp4" controls></video>

  </div>

  <div class="entry-meta">
    <div class="date">2019.12.07/records </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/bozen">Bozen</a></h2>
  <!--<div class="meta"></div>-->


  <img src="/media/2019-12-07_150148.jpg">

        <div class="sf" id="2019-12-07_Bozen_F01.ogg"></div>
        <div class="sf" id="2019-12-07_Bozen_F02.ogg"></div>

  <p>A handheld zoom capturing a waterfalls fed through Microbrute sequenced filter formed the basis for later keyboard overdubs.</p>
  </div>

  <div class="entry-meta">
    <div class="date">2019.12.05/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/bozen-t02">Bozen T02</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->


  <img src="/media/2019-12-06.jpg">

        <div class="sf" id="2019-12-05_122648-LR.ogg"></div>
        <div class="sf" id="2019-12-05_122912-LR.ogg"></div>
        <div class="sf" id="2019-12-05_122912-Tr1.ogg"></div>

  </div>

  <div class="entry-meta">
    <div class="date">2019.12.03/records | <a href="/field-recording/">field recording</a>   </div>
  </div>
  <div class="entry-content">
  <h2><a href="/records/bozen-t01">Bozen T01</a></h2>
  <!--<div class="meta">  <a href="/field-recording/">field recording</a>  </div>-->


  <img src="/media/2019-12-05_114608.jpg">

        <div class="sf" id="2019-12-03_121832-Tr2.ogg"></div>
        <div class="sf" id="2019-12-03_122620-Tr2.ogg"></div>
        <div class="sf" id="2019-12-03_185142-LR.ogg"></div>
        <div class="sf" id="2019-12-03_185338-LR.ogg"></div>
        <div class="sf" id="2019-12-03_185454-LR.ogg"></div>

  </div>
  </section>

  <section id="wavesurfer-gui">
    <div id="gui">
      <a id="flip" href="">toggle waveform</a><br>
      <a id="toggleChrome" href="">options</a>
       <div class="chrome" style="margin-bottom:0.5em; width:200px;">
        <button type="button"><label for="loginput">load log from disk</label></button>
        <input type="file" id="loginput" style="visibility:hidden;width:0px;"/>

        <button onclick="loadVid()" type="button">load vid</button>
        <button onclick="offsetRegions(-44.322)" type="button">offset regions</button>
        <button onclick="removeCloseRegions()" type="button">remove close regions</button>
        <button onclick="saveRegions()" type="button">save regions to disk</button>

        <button onclick="saveRegionsToServer()" type="button">save regions to server</button>
        <button onclick="exportReaperProject()" type="button">export rpp</button>
      </div>
    </div>

    <div id="panel">
      <section>
        <div id="waveform">
          <span id="sfname"></span>
          <div id="progress"></div>
        </div>
      </section>

      <div class="chrome">
        <button data-action="play">play/pause</button>
        zoom: <input data-action="zoom" type="range" min="1" max="400" value="0" style="width: 300px" />
        <span id="time-current">0:00</span> / <span id="time-total">0:00</span>
      </div>
      <input id = "inputtext" type="text" onkeyup="handle(event)">
    </div>

    <script src="/theme/js/jquery-3.5.1.min.js"></script>
    <script src="/theme/js/wavesurfer.js"></script>
    <script src="/theme/js/wavesurfer.regions.min.js"></script>
    <script src="/theme/js/wavesurfer.cursor.js"></script>
    <script src="/theme/js/FileSaver.js"></script>
    <script src="/theme/js/app.js"></script>
  </section>
</body>
</html>